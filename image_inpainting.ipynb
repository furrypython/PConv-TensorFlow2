{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image-inpainting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNilOb1k+DDRyXpRFnIrBxv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/furrypython/PConv-Tensorflow2/blob/master/image_inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPgt033S90Vi",
        "colab_type": "text"
      },
      "source": [
        "# Dogs vs Cats Image Inpainting With Partial Convolution  \n",
        "Unofficial implementation of [Liu et al., 2018. Image Inpainting for Irregular Holes Using Partial Convolutions](https://arxiv.org/abs/1804.07723)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyZrBjnMP0RC",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive to Google Colaboratory \n",
        "Load your data on Google Drive into Google Colaboratory. You can skip this part if you don't use Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O65Q5XAiAjfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "sys.path.append('/gdrive/My Drive/PConv-Tensorflow2/libs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swNfqgwGD3_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eclLWTR2N3eq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from process_data import create_input_pipeline, create_input_pipeline_test, create_input_dataset\n",
        "from pconv2d_layer import PConv2D\n",
        "from pconv_model import build_pconv_unet\n",
        "from loss import get_vgg16_weights, StyleModel\n",
        "from train import fit"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "# Load Data\n",
        "Referencing <a href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l05c01_dogs_vs_cats_without_augmentation.ipynb#scrollTo=KwQtSOz0VrVX\" target=\"_blank\">this</a> Colab, we use a filtered version of <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs. Cats</a> dataset here. \n",
        "Let's directly download the dataset from a URL and unzip it to the Colab filesystem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpIWj9S9JARH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysYCgGT6JGwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzbX3vyaJRU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tdsI_L-NVrV_"
      },
      "source": [
        "# Setting Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2QSPhlkVwu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SHAPE  = 256\n",
        "BATCH_SIZE = 5\n",
        "EPOCHS = 30\n",
        "EPOCHS_FT = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0MbT61IYQXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The weights files directory\n",
        "weights_dir = '/gdrive/My Drive/PConv-Tensorflow2/weights'\n",
        "# The weights files directory\n",
        "checkpoints_dir = weights_dir + '/ckpts'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaA6tgWb5Fgp",
        "colab_type": "text"
      },
      "source": [
        "Port the VGG16 weights from PyTorch <a href=\"https://github.com/ezavarygin/vgg16_pytorch2keras\" target=\"_blank\">this</a> way. The weights file will be used in loss calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcTNu5F45FKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the VGG16 model for loss calculation\n",
        "get_vgg16_weights(weights_dir)\n",
        "vgg16_weights = weights_dir + '/vgg16_pytorch2keras.h5'\n",
        "vgg16 = StyleModel(weights=vgg16_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi43r0CL5UZ4",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klZJR_1KZIPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the training dataset\n",
        "train_dataset = create_input_pipeline(train_dir, batch_size=BATCH_SIZE)\n",
        "# Prepare the validation dataset\n",
        "val_dataset = create_input_pipeline(validation_dir, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pme-vCpsTxlw",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Training images  \n",
        "Let's visualize how a single batch would look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElGGXiXlslPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  title = ['Input Masked Image', 'Input Mask Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.tight_layout()\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KLMjkJjssXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for target_batch in train_dataset.take(1):\n",
        "  (masked_batch, mask_batch), target_batch = create_input_dataset(target_batch, batch_size=BATCH_SIZE)\n",
        "\n",
        "for b in range(BATCH_SIZE):\n",
        "  display([masked_batch[b], mask_batch[b], target_batch[b]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7k8LPPDfyVf",
        "colab_type": "text"
      },
      "source": [
        "# Train Model\n",
        "The model was trained in two steps:  \n",
        "- **Part 1: Initial training** \n",
        "  - The Batch Normalization parameters enabled.\n",
        "  - 30 epochs with a learning rate of 0.0002.  \n",
        "- **Part2: Fine-tuning**  \n",
        "  - The Batch Normalization parameters freezed in the encoder part of the network.\n",
        "  - 8 epochs with a learning rate of 0.00005."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTcYmHWGeEiK",
        "colab_type": "text"
      },
      "source": [
        "## Initial training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re_3GnzLLWCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_pconv_unet(img_shape=IMG_SHAPE)\n",
        "opt_train_01 = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "history_01 = fit(model=model, \n",
        "                 input_data=iter(train_dataset), \n",
        "                 batch_size=BATCH_SIZE, \n",
        "                 epochs=EPOCHS, \n",
        "                 steps_per_epoch=400, \n",
        "                 validation_data=iter(val_dataset),  \n",
        "                 validation_steps=250, \n",
        "                 vgg16=vgg16, \n",
        "                 optimizer=opt_train_01, \n",
        "                 save_dir=checkpoints_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9agWlwcnGcVU",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyb6gLhoG_Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_pconv_unet(img_shape=IMG_SHAPE, fine_tuning=True)\n",
        "model.load_weights(checkpoints_dir + '/epoch-29-2020-07-24-05-25-31.h5')\n",
        "opt_train_02 = tf.keras.optimizers.Adam(learning_rate=0.00005)\n",
        "\n",
        "history_02 = fit(model=model, \n",
        "                 input_data=iter(train_dataset), \n",
        "                 batch_size=BATCH_SIZE, \n",
        "                 epochs=15, \n",
        "                 steps_per_epoch=400, \n",
        "                 validation_data=iter(val_dataset), \n",
        "                 validation_steps=250, \n",
        "                 vgg16=vgg16,  \n",
        "                 optimizer=opt_train_02, \n",
        "                 save_dir=checkpoints_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRC8ic1c5K_G",
        "colab_type": "text"
      },
      "source": [
        "# Visualize Results of the Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52WNeUc36CbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The test images directory\n",
        "test_dir = '/gdrive/My Drive/PConv-Tensorflow2/dataset/test'\n",
        "test_dataset = create_input_pipeline_test(test_dir, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0DY0ZwPKQS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_pconv_unet(img_shape=IMG_SHAPE)\n",
        "model.load_weights(checkpoints_dir + '/epoch-7-2020-07-24-06-42-17.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-ZWi6ndLOaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for test_target_batch in test_dataset.take(1):\n",
        "  (test_masked_batch, test_mask_batch), test_target_batch = create_input_dataset(test_target_batch, batch_size=BATCH_SIZE)\n",
        "test_result = model.predict([test_masked_batch, test_mask_batch])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHNxhv3VBT72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for idx in range(BATCH_SIZE):\n",
        "  display([test_masked_batch[idx], test_mask_batch[idx], test_target_batch[idx], test_result[idx]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PehOzSqLJBCR",
        "colab_type": "text"
      },
      "source": [
        "## Visualize Learninsg Curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39fAyp0RIK5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_01 = np.array(history_01['loss'])\n",
        "loss_02 = np.array(history_02['loss'])\n",
        "loss = np.concatenate([loss_01, loss_02])\n",
        "\n",
        "val_loss_01 = np.array(history_01['val_loss'])\n",
        "val_loss_02 = np.array(history_01['val_loss'])\n",
        "val_loss = np.concatenate([val_loss_01, val_loss_02])\n",
        "\n",
        "total_epochs = np.arange(0, EPOCHS+EPOCHS_FT)\n",
        "plt.title('Learning Curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss value')\n",
        "plt. plot(total_epochs, loss, label='train')\n",
        "plt. plot(total_epochs, val_loss, label='validation')\n",
        "# The border which represents the end of initial train & start of fine-tuning.\n",
        "plt.axvline(total_epochs=EPOCHS, linewidth=1, color='gray', linestyle='--')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}